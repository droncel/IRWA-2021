{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval and Web Analytics Project\n",
    "## Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Packages\n",
    "\n",
    "We first import all the packages that we need for text processing, such as:\n",
    "- Demoji\n",
    "- Re\n",
    "- Deep translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/martinacarres/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import string\n",
    "from array import array\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import nltk\n",
    "import demoji\n",
    "import re\n",
    "nltk.download('stopwords');\n",
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the file with the tweets:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_path = 'dataset_tweets_WHO.txt'\n",
    "\n",
    "# Read the JSON file in a unique string\n",
    "with open(docs_path) as fp:\n",
    "    corpus = fp.readlines()[0]\n",
    "\n",
    "# Load the JSON file as a dictionary\n",
    "corpus = json.loads(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are \u001b[1m2399 tweets\u001b[0m in the dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \\033[1m%i tweets\\033[0m in the dataset\" %len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def italics_to_plaintext(text):\n",
    "    #difference between an italic lowecase character and its corresponding plaintext lowercase character\n",
    "    diff_lower = ord('ğ˜¢') - ord('a')\n",
    "    #difference between an italic uppercase character and its corresponding plaintext uppercase character\n",
    "    diff_upper = ord('ğ˜ˆ') - ord('A')\n",
    "    \n",
    "    plaintext = \"\"\n",
    "    for c in text:\n",
    "        # if the character is italic lowercase, get the corresponding plaintext lowercase character\n",
    "        if ord(c) >= ord('ğ˜¢') and ord(c) <= ord('ğ˜»'):\n",
    "            plaintext += chr(ord(c) - diff_lower)\n",
    "        # else if the character is italic uppercase, get the corresponding plaintext uppercase character\n",
    "        elif ord(c) >= ord('ğ˜ˆ') and  ord(c) <= ord('ğ˜¡'):\n",
    "            plaintext += chr(ord(c) - diff_upper)\n",
    "        else:\n",
    "            plaintext += c\n",
    "    \n",
    "    return plaintext\n",
    "\n",
    "def bold_to_plaintext(text):\n",
    "    #difference between a bold lowecase character and its corresponding plaintext lowercase character\n",
    "    diff_lower = ord('ğš') - ord('a')\n",
    "    #difference between a bold uppercase character and its corresponding plaintext uppercase character\n",
    "    diff_upper = ord('ğ€') - ord('A')\n",
    "    \n",
    "    plaintext = \"\"\n",
    "    for c in text:\n",
    "        # if the character is bold lowercase, get the corresponding plaintext lowercase character\n",
    "        if ord(c) >= ord('ğš') and ord(c) <= ord('ğ³'):\n",
    "            plaintext += chr(ord(c) - diff_lower)\n",
    "        # else if the character is bold uppercase, get the corresponding plaintext uppercase character\n",
    "        elif ord(c) >= ord('ğ€') and  ord(c) <= ord('ğ™'):\n",
    "            plaintext += chr(ord(c) - diff_upper)\n",
    "        else:\n",
    "            plaintext += c\n",
    "    \n",
    "    return plaintext\n",
    "\n",
    "def getTerms(text, stemming, stops):\n",
    "    # Text to lowercase\n",
    "    text = text.lower()\n",
    "    # Text delete italic letter type if needed\n",
    "    text = italics_to_plaintext(text)\n",
    "    # Text delete bold letter type if needed\n",
    "    text = bold_to_plaintext(text)\n",
    "    # Delete all urls\n",
    "    text = re.sub(r'http\\S+', ' ', text) \n",
    "    # Delete all non-alphanumerical characters (it includes emojis) except '#' and '@'\n",
    "    text = re.sub(r'[^A-Za-z0-9#@]+', ' ', text)\n",
    "    # Text tokenization\n",
    "    words = text.split()\n",
    "    # Remove stopwords\n",
    "    words = [word for word in words if word not in stops]\n",
    "    # Get the stem of each word\n",
    "    words = [stemming.stem(word) for word in words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stemming = PorterStemmer()\n",
    "# Delete also \"amp\" (&) and \"rt\"\n",
    "stops = set(stopwords.words(\"english\")).union(set({'amp', 'rt'}))\n",
    "\n",
    "# Dictionary where we'll save all the processed tweets\n",
    "data = {}\n",
    "for tweet in corpus:\n",
    "    \n",
    "    #In case that the tweet is not in english, we traduce it\n",
    "    lang = corpus[tweet]['lang']\n",
    "    if lang != 'en':\n",
    "        text_tweet = GoogleTranslator(target='en').translate(corpus[tweet]['full_text'])\n",
    "    else:\n",
    "        text_tweet = corpus[tweet]['full_text']\n",
    "    \n",
    "    # Get the text tokenized and cleaned \n",
    "    text_tweet_processed = getTerms(text_tweet, stemming, stops)\n",
    "    \n",
    "    if text_tweet_processed != []: #In case that the text is not null                       \n",
    "        data[tweet] = {}\n",
    "        data[tweet]['text'] = text_tweet_processed\n",
    "\n",
    "        # Save all emojis used with its meaning\n",
    "        data[tweet]['emojis'] = demoji.findall(corpus[tweet]['full_text'])\n",
    "\n",
    "        # Save creation data\n",
    "        data[tweet]['date'] = corpus[tweet]['created_at']\n",
    "\n",
    "        # Save the number of retweets of this tweet\n",
    "        data[tweet]['retweets'] = corpus[tweet]['retweet_count']\n",
    "\n",
    "        # Save the number of 'favorites' of this tweet\n",
    "        data[tweet]['favorites'] = corpus[tweet]['favorite_count']\n",
    "\n",
    "        # Save the full name of all the users mentioned\n",
    "        data[tweet]['user_mentions'] = list()\n",
    "        ## List of dictionaries, each with information of a user mentioned\n",
    "        users_data = corpus[tweet]['entities']['user_mentions']\n",
    "        for user in users_data:\n",
    "            data[tweet]['user_mentions'].append(user['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spanish Tweet with emojis:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_text\n",
      "RT @opsoms: Si estÃ¡ completamente vacunado ğŸ’‰ğŸ’‰, Â¿aÃºn puede contraer COVID-19? \n",
      "\n",
      "ğŸš¨ No importa si estÃ¡ vacunado o si todavÃ­a estÃ¡ esperando, sâ€¦\n",
      "--------------------------------------------------\n",
      "created_at\n",
      "Wed Oct 13 05:47:10 +0000 2021\n",
      "--------------------------------------------------\n",
      "retweet_count\n",
      "43\n",
      "--------------------------------------------------\n",
      "favorite_count\n",
      "0\n",
      "--------------------------------------------------\n",
      "entities\n",
      "{'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'opsoms', 'name': 'OPS/OMS', 'id': 22276965, 'id_str': '22276965', 'indices': [3, 10]}], 'urls': []}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Before processing\n",
    "features = ['full_text', 'created_at', 'retweet_count', 'favorite_count', 'entities']\n",
    "for feature in features:\n",
    "    print(feature)\n",
    "    print(corpus['4'][feature])\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['@opsom',\n",
       "  'fulli',\n",
       "  'vaccin',\n",
       "  'still',\n",
       "  'get',\n",
       "  'covid',\n",
       "  '19',\n",
       "  'matter',\n",
       "  'vaccin',\n",
       "  'still',\n",
       "  'wait',\n",
       "  'ye'],\n",
       " 'emojis': {'ğŸ’‰': 'syringe', 'ğŸš¨': 'police car light'},\n",
       " 'date': 'Wed Oct 13 05:47:10 +0000 2021',\n",
       " 'retweets': 43,\n",
       " 'favorites': 0,\n",
       " 'user_mentions': ['OPS/OMS']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After processing\n",
    "data['4']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example where saving the full name of the user can be useful:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_text\n",
      "RT @DrTedros: Was good to meet @Chikwe_I, who will soon head our work on health emergency surveillance, incl the @WHO Hub for Pandemic &amp; Epâ€¦\n",
      "--------------------------------------------------\n",
      "entities\n",
      "{'hashtags': [], 'symbols': [], 'user_mentions': [{'screen_name': 'DrTedros', 'name': 'Tedros Adhanom Ghebreyesus', 'id': 189868631, 'id_str': '189868631', 'indices': [3, 12]}, {'screen_name': 'Chikwe_I', 'name': 'Chikwe Ihekweazu', 'id': 3387606493, 'id_str': '3387606493', 'indices': [31, 40]}, {'screen_name': 'WHO', 'name': 'World Health Organization (WHO)', 'id': 14499829, 'id_str': '14499829', 'indices': [113, 117]}], 'urls': []}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Before processing\n",
    "features = ['full_text', 'entities']\n",
    "for feature in features:\n",
    "    print(feature)\n",
    "    print(corpus['15'][feature])\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['@drtedro',\n",
       "  'good',\n",
       "  'meet',\n",
       "  '@chikw',\n",
       "  'soon',\n",
       "  'head',\n",
       "  'work',\n",
       "  'health',\n",
       "  'emerg',\n",
       "  'surveil',\n",
       "  'incl',\n",
       "  '@who',\n",
       "  'hub',\n",
       "  'pandem',\n",
       "  'ep'],\n",
       " 'emojis': {},\n",
       " 'date': 'Tue Oct 12 16:27:05 +0000 2021',\n",
       " 'retweets': 84,\n",
       " 'favorites': 0,\n",
       " 'user_mentions': ['Tedros Adhanom Ghebreyesus',\n",
       "  'Chikwe Ihekweazu',\n",
       "  'World Health Organization (WHO)']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After processing\n",
    "data['15']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of tweet in italics:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğ˜ğ˜µ'ğ˜´ ğ˜–ğ˜’ ğ˜µğ˜° ğ˜¢ğ˜´ğ˜¬ ğ˜´ğ˜°ğ˜®ğ˜¦ğ˜°ğ˜¯ğ˜¦ ğ˜ªğ˜§ ğ˜µğ˜©ğ˜¦ğ˜º ğ˜¢ğ˜³ğ˜¦ ğ˜µğ˜©ğ˜ªğ˜¯ğ˜¬ğ˜ªğ˜¯ğ˜¨ ğ˜¢ğ˜£ğ˜°ğ˜¶ğ˜µ #ğ˜´ğ˜¶ğ˜ªğ˜¤ğ˜ªğ˜¥ğ˜¦ - ğ˜ªğ˜µ ğ˜°ğ˜§ğ˜µğ˜¦ğ˜¯ ğ˜³ğ˜¦ğ˜¥ğ˜¶ğ˜¤ğ˜¦ğ˜´ ğ˜¢ğ˜¯ğ˜¹ğ˜ªğ˜¦ğ˜µğ˜º ğ˜¢ğ˜¯ğ˜¥ ğ˜©ğ˜¦ğ˜­ğ˜±ğ˜´ ğ˜±ğ˜¦ğ˜°ğ˜±ğ˜­ğ˜¦ ğ˜§ğ˜¦ğ˜¦ğ˜­ ğ˜¶ğ˜¯ğ˜¥ğ˜¦ğ˜³ğ˜´ğ˜µğ˜°ğ˜°ğ˜¥.\n",
      " \n",
      "#WorldMentalHealthDay #LetsTalk https://t.co/KO4YKmGxGL\n"
     ]
    }
   ],
   "source": [
    "# Before processing\n",
    "print(corpus['90']['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['it',\n",
       "  'ok',\n",
       "  'ask',\n",
       "  'someon',\n",
       "  'think',\n",
       "  '#suicid',\n",
       "  'often',\n",
       "  'reduc',\n",
       "  'anxieti',\n",
       "  'help',\n",
       "  'peopl',\n",
       "  'feel',\n",
       "  'understood',\n",
       "  '#worldmentalhealthday',\n",
       "  '#letstalk'],\n",
       " 'emojis': {},\n",
       " 'date': 'Sun Oct 10 11:34:03 +0000 2021',\n",
       " 'retweets': 127,\n",
       " 'favorites': 286,\n",
       " 'user_mentions': []}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After processing\n",
    "data['90']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of tweet in bold:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@DrTedros @antonioguterres \"ğ–ğ ğ¡ğšğ¯ğ ğ­ğ¡ğ ğ­ğ¨ğ¨ğ¥ğ¬ ğ­ğ¨ ğ›ğ«ğ¢ğ§ğ  ğ­ğ¡ğ #ğ‚ğğ•ğˆğƒğŸğŸ— ğ©ğšğ§ğğğ¦ğ¢ğœ ğ®ğ§ğğğ« ğœğ¨ğ§ğ­ğ«ğ¨ğ¥, ğ¢ğŸ ğ°ğ ğ®ğ¬ğ ğ­ğ¡ğğ¦ ğ©ğ«ğ¨ğ©ğğ«ğ¥ğ² ğšğ§ğ ğ¬ğ¡ğšğ«ğ ğ­ğ¡ğğ¦ ğŸğšğ¢ğ«ğ¥ğ²\"-@DrTedros #VaccinEquity\n"
     ]
    }
   ],
   "source": [
    "# Before processing\n",
    "print(corpus['187']['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['@drtedro',\n",
       "  '@antonioguterr',\n",
       "  'we',\n",
       "  'tool',\n",
       "  'bring',\n",
       "  '#covid',\n",
       "  'pandem',\n",
       "  'control',\n",
       "  'use',\n",
       "  'properli',\n",
       "  'share',\n",
       "  'fairli',\n",
       "  '@drtedro',\n",
       "  '#vaccinequ'],\n",
       " 'emojis': {},\n",
       " 'date': 'Thu Oct 07 13:53:01 +0000 2021',\n",
       " 'retweets': 51,\n",
       " 'favorites': 209,\n",
       " 'user_mentions': ['Tedros Adhanom Ghebreyesus',\n",
       "  'AntÃ³nio Guterres',\n",
       "  'Tedros Adhanom Ghebreyesus']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After processing\n",
    "data['187']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
